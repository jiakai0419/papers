# LLM Papers

## Scaling
* [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) 2022.03
* [Predicting Emergent Abilities with Infinite Resolution Evaluation](https://arxiv.org/abs/2310.03262) 2023.10
* [The Platonic Representation Hypothesis](https://arxiv.org/abs/2405.07987) 2024.05

## Architecture
* [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf) 2017.06
* [Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf) 2018.06
* [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf) 2018.10
* [DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models](https://arxiv.org/pdf/2401.06066.pdf) 2024.01

## Alignment
* [Scaling Instruction-Finetuned Language Models](https://arxiv.org/abs/2210.11416) 2022.10
* [Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/abs/2303.11366) 2023.03
* [RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment](https://arxiv.org/abs/2304.06767) 2023.04
* [WizardLM: Empowering Large Language Models to Follow Complex Instructions](https://arxiv.org/abs/2304.12244) 2023.04
* [LIMA: Less Is More for Alignment](https://arxiv.org/abs/2305.11206) 2023.05
* [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290) 2023.05
* [Mixture-of-Experts Meets Instruction Tuning: A Winning Combination for Large Language Models](https://arxiv.org/abs/2305.14705) 2023.05
* [Preference Ranking Optimization for Human Alignment](https://arxiv.org/abs/2306.17492) 2023.06
* [Orca: Progressive Learning from Complex Explanation Traces of GPT-4](https://arxiv.org/abs/2306.02707) 2023.06
* [Self-Alignment with Instruction Backtranslation](https://arxiv.org/abs/2308.06259) 2023.08
* [Taken out of context: On measuring situational awareness in LLMs](https://arxiv.org/abs/2309.00667) 2023.09
* [RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback](https://arxiv.org/abs/2309.00267) 2023.09
* [Self-Rewarding Language Models](https://arxiv.org/abs/2401.10020) 2024.01
* [A Survey of Monte Carlo Tree Search Methods](http://www.incompleteideas.net/609%20dropbox/other%20readings%20and%20resources/MCTS-survey.pdf) 2012.03
* [From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models](https://arxiv.org/abs/2404.15846) 2024.04
* [From Instructions to Constraints: Language Model Alignment with Automatic Constraint Verification](https://arxiv.org/abs/2403.06326) 2024.03
* [COLLIE: Systematic Construction of Constrained Text Generation Tasks](https://arxiv.org/abs/2307.08689) 2023.07
* [Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models](https://arxiv.org/abs/2404.02823) 2024.04

## Scalable Oversight
* [Self-critiquing models for assisting human evaluators](https://arxiv.org/abs/2206.05802) 2022.06
* [Weak-to-strong generalization](https://cdn.openai.com/papers/weak-to-strong-generalization.pdf) 2023.12

## ICL
* [Larger language models do in-context learning differently](https://arxiv.org/abs/2303.03846) 2023.03
* [Many-Shot In-Context Learning](https://arxiv.org/pdf/2404.11018v1.pdf) 2024.04

## Math & Reasoning
* [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903) 2022.01
* [Let’s Verify Step by Step](https://arxiv.org/abs/2305.20050) 2023.05
* [Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks](https://arxiv.org/abs/2305.14201) 2023.05
* [Math-Shepherd: Verify and Reinforce LLMs Step-by-step without Human Annotations](https://arxiv.org/abs/2312.08935) 2023.12
* [Solving olympiad geometry without human demonstrations](https://www.nature.com/articles/s41586-023-06747-5) 2024.01
* [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/abs/2402.03300) 2024.02
* [AlphaMath Almost Zero: process Supervision without process](https://arxiv.org/abs/2405.03553) 2024.05
* [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601) 2023.05

## Report
* [GPT-4 Architecture, Infrastructure, Training Dataset, Costs, Vision, MoE]() 2023.07
* [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288) 2023.07
* [Gemini 1.0](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf) 2023.12
* [Gemini 1.5](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf) 2024.02

## Talk & Blog
* [State of GPT](https://karpathy.ai/stateofgpt.pdf) 2023.05
* [Some intuitions about large language models](https://docs.google.com/presentation/d/1hQUd3pF8_2Gr2Obc89LKjmHL0DlH-uof9M0yFVd3FA4/edit#slide=id.g16197112905_0_0) 2023.11
* [MiniCPM：揭示端侧大语言模型的无限潜力](https://shengdinghu.notion.site/MiniCPM-c805a17c5c8046398914e47f0542095a) 2024.04
* [Llama 3 Opens the Second Chapter of the Game of Scale](https://yaofu.notion.site/Apr-2024-Llama-3-Opens-the-Second-Chapter-of-the-Game-of-Scale-efff1c0c185f4008af673b78faf83b61) 2024.04
* [Successful language model evals](https://www.jasonwei.net/blog/evals) 2024.05

## Evaluation
* [Challenging BIG-Bench tasks and whether chain-of-thought can solve them](https://arxiv.org/abs/2210.09261) 2022.10
* [Instruction-Following Evaluation for Large Language Models](https://arxiv.org/abs/2311.07911) 2023.11
* [FollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models](https://arxiv.org/abs/2310.20410) 2023.10

## Quality
* [Scaling Laws and Interpretability of Learning from Repeated Data](https://arxiv.org/abs/2205.10487) 2022.05

## Efficient
* [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685) 2021.06

## Merging
* [Evolutionary Optimization of Model Merging Recipes](https://sakana.ai/evolutionary-model-merge/) 2024.03

## Model Spec 
* [OpenAI Model Spec 240508](https://cdn.openai.com/spec/model-spec-2024-05-08.html) 2024.05

# Multimodality Papers
* [Video generation models as world simulators](https://openai.com/research/video-generation-models-as-world-simulators) 2024.02

